{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "electoral-portland",
   "metadata": {},
   "source": [
    "# Naive-Bayes (DMC 2003, SPAM-Erkennung)\n",
    "\n",
    "## Metriken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6c86c6",
   "metadata": {},
   "source": [
    "Satz von Bayes:\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac{P(A) \\cdot P(B | A)}{P(B)}\n",
    "$$\n",
    "\n",
    "Klasse $C_k$ in Abhängigkeit der Features $X = (x_1,\\,\\dots,\\,x_n)$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(C_k|X) &= \\frac{P(C_k) \\cdot P(X|C_k)}{P(X)} \\\\\n",
    "&= \\frac{P(C_k) \\cdot P(x_1 \\land x_2 \\dots \\land x_n | C_k)}{P(x_1 \\land x_2 \\dots \\land x_n)}\\\\\n",
    "&= \\alpha \\cdot P(C_k) \\cdot P(x_1 \\land x_2 \\dots \\land x_n | C_k),\\quad \\alpha\\; \\text{const}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "»Naive« Annahme: alle $x_i$ stochastisch unabhängig.\n",
    "\n",
    "$$\n",
    "P(C_k|X) =  \\alpha \\cdot P(C_k) \\cdot \\prod_{i=1}^n P(x_i|C_k)\n",
    "$$\n",
    "\n",
    "Wahrscheinlichste Klasse:\n",
    "\n",
    "$$\n",
    "\\hat{k} = \\text{argmax}_k P(C_k)\\prod_i P(x_i|C_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-colombia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection, preprocessing\n",
    "from sklearn import naive_bayes, metrics, linear_model, dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-freeze",
   "metadata": {},
   "source": [
    "Einlesen Data Frame, Spaltentrenner ist das Leerzeichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-superior",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData = pd.read_csv('data_dmc2003_train.txt', sep=' ')\n",
    "dfData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-pulse",
   "metadata": {},
   "source": [
    "Analyse der Zielwerte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-header",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-transcription",
   "metadata": {},
   "source": [
    "Aufteilen in Features und Zielgröße. Umwandeln der Zielgröße in Zahl. Aufteilen in Trainings- und Testmenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFeatures = dfData.drop(['id', 'target'], axis=1).values\n",
    "target = dfData.target.map({'no': 0, 'yes': 1}).values\n",
    "Xtrain, Xtest, yTrain, yTest = model_selection.train_test_split(\n",
    "    dataFeatures, target, test_size=0.3, random_state=23)\n",
    "Xtrain.shape, yTrain.shape, Xtest.shape, yTest.shape, Xtrain.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-spank",
   "metadata": {},
   "source": [
    "Untersuchen Wertebereich Features. Nur Werte von 0 und 1 treten auf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a846a6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_train, counts_train = np.unique(Xtrain, return_counts=True)\n",
    "print('Train: different values', vals_train, 'Counts', counts_train)\n",
    "vals_test, counts_test = np.unique(Xtest, return_counts=True)\n",
    "print('Test:  different values', vals_test, 'Counts', counts_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-window",
   "metadata": {},
   "source": [
    "Test auf Fehlwerte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-furniture",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(np.isnan(Xtrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-restoration",
   "metadata": {},
   "source": [
    "Naive-Bayes-Klassifikation. ``alpha`` ist ein Regulierungsparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-bacon",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = naive_bayes.BernoulliNB()\n",
    "classifier.fit(Xtrain, yTrain)\n",
    "print('Train:', classifier.score(Xtrain, yTrain), 'Test:', classifier.score(Xtest, yTest))\n",
    "predTest = classifier.predict(Xtest)\n",
    "print(metrics.confusion_matrix(yTest, predTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f62906",
   "metadata": {},
   "source": [
    "## Erläuterung Confusion Matrix\n",
    "\n",
    "~~~~\n",
    "       Vorhersage\n",
    "         0  1\n",
    "-------------\n",
    "GT: 0 | tn fp\n",
    "    1 | fn tp ← Recall\n",
    "            ↑\n",
    "            Precision\n",
    "~~~~\n",
    "\n",
    "- Vorhergesagte positive Werte: tp + fp\n",
    "- Tatsächliche positive Werte:  tp + fn\n",
    "- Precision: tp/(tp + fp) – welcher Anteil der positiv vorhergesagten Werte ist wirklich positiv\n",
    "- Recall:    tp/(tp + fn) – welcher Anteil der wirklich positiven Werte wurde als positiv vorhergesagt\n",
    "- Entscheidungschwelle senken: mehr positive erkannt, Recall ↑, Precision ↓\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bad952e",
   "metadata": {},
   "source": [
    "Vorhersage von Wahrscheinlichkeiten. Shape ist (ZahlDatensätze, ZahlKlassen). Wir benötigen nur Klasse 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edb517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "probTest = classifier.predict_proba(Xtest)[:,1]\n",
    "probTest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff016b11",
   "metadata": {},
   "source": [
    "Einfluss der Entscheidungsschwelle. Nur Wahrscheinlichkeiten > Schwelle werden als positiv klassifiziert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8112d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.8\n",
    "plt.scatter(yTest, probTest, c=(probTest >= threshold) == yTest, alpha=0.2)\n",
    "plt.hlines(threshold, 0, 1)\n",
    "plt.xlabel('GT')\n",
    "plt.ylabel('Pred')\n",
    "plt.xticks([0,1])\n",
    "print('Oben: Precision, rechts: Recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cba0388",
   "metadata": {},
   "source": [
    "Graphische Darstellung für verschiedene Schwellwerte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554ec25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0, 0.99, 50)\n",
    "prec_rec = list()\n",
    "for threshold in thresholds:\n",
    "    predTest = probTest >= threshold\n",
    "    precision = metrics.precision_score(yTest, predTest, zero_division=0)\n",
    "    recall    = metrics.recall_score(yTest, predTest)\n",
    "    f1 = metrics.f1_score(yTest, predTest)\n",
    "    prec_rec.append(np.array([precision, recall, f1]))\n",
    "prec_rec = np.stack(prec_rec)\n",
    "prec_rec\n",
    "plt.plot(thresholds, prec_rec[:,0], label='Precision')\n",
    "plt.plot(thresholds, prec_rec[:,1], label='Recall')\n",
    "plt.plot(thresholds, prec_rec[:,2], label='F1')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856e6590",
   "metadata": {},
   "source": [
    "Vergleich logistische Regression und Dummy-Classifier. Beide liefern Wahrscheinlichkeiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76fa4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clRegr = linear_model.LogisticRegression()\n",
    "clRegr.fit(Xtrain, yTrain)\n",
    "yProbRegr = clRegr.predict_proba(Xtest)[:,1]\n",
    "yProbRegr\n",
    "clDummy = dummy.DummyClassifier(strategy='uniform')\n",
    "clDummy.fit(Xtrain, yTrain)\n",
    "yProbDummy = clDummy.predict_proba(Xtest)[:,1]\n",
    "yProbDummy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e02b61",
   "metadata": {},
   "source": [
    "Confusion Matrix für logistische Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8288bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "yPredRegr = yProbRegr >= 0.5\n",
    "metrics.confusion_matrix(yTest, yPredRegr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c475fb6",
   "metadata": {},
   "source": [
    "… und für Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b44e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "yPredDummy = yProbDummy >= 0.5\n",
    "metrics.confusion_matrix(yTest, yPredDummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa30f07",
   "metadata": {},
   "source": [
    "Receiver Operation Characteristics (ROC). Statt Precision und Recall werden False Positive Rate und True Positive Rate verwendet. Optimale Klassifikation: oberes Dreieck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72de4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(yTest, probTest)\n",
    "plt.plot(fpr, tpr, label='Naive Bayes')\n",
    "fpr, tpr, thresholds = metrics.roc_curve(yTest, yProbRegr)\n",
    "plt.plot(fpr, tpr, label='Logistic Regression')\n",
    "fpr, tpr, _ = metrics.roc_curve(yTest, yProbDummy)\n",
    "plt.plot(fpr, tpr, label='Dummy')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
